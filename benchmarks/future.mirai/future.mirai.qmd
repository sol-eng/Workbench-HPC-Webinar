---
title: "future.mirai vs future.cluster"
author: "Michael Mayer"
format: html
editor: visual
execute:
  echo: true
  output: true
---

## future.mirai vs. future.cluster

[future.mirai](https://future.mirai.futureverse.org/) is a new backend for the [futureverse](https://www.futureverse.org/) framework. It uses [mirai](https://shikokuchuo.net/mirai/) as a backend. Mirai is using [nanonext](https://shikokuchuo.net/nanonext/), the R frontend for [NNG](https://nng.nanomsg.org/), a successor for the [zeromq](https://zeromq.org/) framework (the latter being used in the R package [clustermq](https://mschubert.github.io/clustermq/index.html)).

Here we compare the future.mirai backend with the cluster backend. All benchmarks are run on a SLURM based HPC cluster.

For the integration of the cluster backend in the scheduler we use the [slurmR](https://uscbiostats.github.io/slurmR/index.html) package. Due to a missing feature in slurmR, i.e. the ability to specify `rscript_startup` needed for `renv`, we are first creating a cluster object using the `makeSlurmCluster`() function and then use the allocated nodes as workers for the `makeClusterPSOCK()` call.

## Code

### Initial setup

First we load all needed packages

```{r}
#| output: false
library(future.mirai)
library(mirai)
library(slurmR)
library(furrr)
library(purrr)
library(palmerpenguins)
library(dplyr)
library(tibble)
library(ggplot2)
```

We set some quarto option to allow more than the default 128 connections on R 4.4.0+

```{r}
Sys.setenv(QUARTO_KNITR_RSCRIPT_ARGS="--max-connections=1024")
```

### Various function definitions

First we define our compute task function

```{r}
compute_task <- function(n) {
  library(palmerpenguins)
  library(dplyr)
  peng <- penguins %>% 
    filter(!is.na(species) & !is.na(sex)) %>%
    mutate(
      species = as.factor(species),
      sex = as.factor(sex)
    ) %>% 
    sample_n(333)
  res<-glm(body_mass_g ~ species + sex, data = peng)
  
  
  row_numbers <- res$model %>%
    mutate(row_num = row_number()) %>%
    filter(species == "Chinstrap" & sex == "male") %>%
    pull(row_num)
  predict(res)[[row_numbers[[1]]]]
}
```

This task is then run `samples` times in a `future_map` call

```{r}
compute <- function(samples) {
  system.time(res <- 1:samples |>
                future_map(compute_task, .options = furrr_options(
                  seed = TRUE,
                  packages = c("palmerpenguins", "dplyr")
                )))[3]
}
```

Note in the above the mention of `furrr_options` `seed=TRUE` to ensure reproducibilty (random number generation consistency) and the attachment of the two needed packages for the `compute_task` function.

Since we will likely run within a workbench session, we need to make sure that SLURM CLI commands such as `sbatch` and `srun` work and are able to reach outside the current session, for that purpose we clean out all the SLURM environment variables

```{r}
my_envs<-Sys.getenv()
Sys.unsetenv(
  names(
    my_envs[
      sapply("SLURM", 
            function(p) grepl(p, names(my_envs), fixed = TRUE)
            )
      ]
    )
  )
```

Because `mirai` is an asynchronous framework, for our benchmarking purposes we need to ensure that all workers are online before running any actual computations. For this purposes we need an additional helper function

```{r}
wait_for_mirai <- function() {
  cat("waiting for all mirai workers to be online...")
  repeat {
    online_stat <- as.data.frame(mirai::status()$daemons)$online
    online_workers <- length(online_stat[online_stat == 1])
    total_workers <- length(online_stat)
    cat(paste(Sys.time()),
        " ",
        paste(online_workers, "/", total_workers, " online\r"))
    Sys.sleep(1)
    if (length(unique(online_stat)) == 1 &&
        online_stat[1] == "1") {
      break
    }
  }
  cat("all workers online")
}
```

Finally we use the above functions to define our two benchmark functions for `future.mirai` and `future.cluster`

For `future.mirai` we can use the `remote_config()` capability where we can specify our `srun` command.

```{r}
benchmark_mirai <- function(cores, samples, memory = 1024) {
  # setup mirai daemons against SLURM
  daemons(
    cores,
    url = host_url(ws = TRUE, tls = TRUE),
    remote = remote_config(
      command = "sbatch",
      args = c(paste("--mem", memory), paste0("-J mirai-",cores), 
               "-p all", "-n 1", "--wrap", "."),
      rscript = file.path(R.home("bin"), "Rscript"),
      quote = TRUE
    ),
    dispatcher = TRUE
  )
  # wait until all daemons are active
  setup_time <- system.time(wait_for_mirai())[3]
  
  # plan mirai_cluster
  plan(mirai_cluster)
  
  # execute computations and return time
  compute_time <- compute(samples)
  
  # close all mirai daemons
  daemons(0)
  
  return (data.frame(cores, setup_time, compute_time))
}
```

For the `cluster` backend we use the `slurmR` package to get a number of cores allocated. Those cores are then used for the `future` calculation.

```{r}
benchmark_cluster <- function(cores, samples, cwd, memory = 1024) {
  opts_slurmR$set_opts(mem = paste0(memory, "m"), partition = "all")
  #allocate compute nodes via slurmR
  cl_slurm <- makeSlurmCluster(cores, max_wait = 600)
  
  workers <- sapply(cl_slurm, "[[", 2)
  stopCluster(cl_slurm)
  
  setup_time <- system.time(cl <- makeClusterPSOCK(
    workers,
#    rscript_args = c("--max-connections=1024"),
    rscript_startup = paste0('.libPaths("', .libPaths()[1], '")')
  ))[3]
  
  # plan cluster future
  plan(cluster, workers = cl)
  
  # run computation
  compute_time <- compute(samples)
  
  # stop cluster
  stopCluster(cl)
  
  return (data.frame(cores, setup_time, compute_time))
}
```

### Run the benchmark

First, we run the benchmark on 1 to 256 cores in factors of sqrt(2) increments.

```{r}
#| output: false
library(purrr)
library(dplyr)

cores <- 2 ** (0:7)
samples <- c(2500) #,5000,10000,25000,50000,100000)

params<-expand.grid(cores=cores,samples=samples)

df <- map2_dfr(params$cores, params$samples, function(cores,samples) {
  memory <- 1024 
  cluster_time <- benchmark_cluster(cores, samples, memory = memory) %>% 
    mutate(type = "cluster")
  mirai_time <- benchmark_mirai(cores, samples, memory = memory) %>% 
    mutate(type = "mirai")
  bind_rows(mirai_time, cluster_time)
})

base_time_cluster <- df %>%
  filter(type == "cluster", cores == 1) %>%
  select(samples, compute_time) %>%
  rename(base_compute_time_cluster = compute_time)

base_time_mirai <- df %>%
  filter(type == "mirai", cores == 1) %>%
  select(samples, compute_time) %>%
  rename(base_compute_time_mirai = compute_time)



df <- df %>%
  left_join(base_time_mirai, by = "samples") %>%
  left_join(base_time_cluster, by = "samples") %>%
  mutate(
    speedup = if_else(
      type == "mirai",
      base_compute_time_mirai / compute_time,
      base_compute_time_cluster / compute_time
    )
  )
```

### Analyze and plot the results

Finally we plot the results

```{r}
library(ggplot2)

# Define color palettes for each type
mirai_colors <- colorRampPalette(c("green", "blue"))(length(unique(df$samples)))
cluster_colors <- colorRampPalette(c("orange", "red"))(length(unique(df$samples)))

# Create a named vector of colors for the interaction levels
interaction_levels <- interaction(df$samples, df$type, drop = TRUE)
colors <- sapply(levels(interaction_levels), function(level) {
  parts <- strsplit(level, "\\.")[[1]]
  sample_value <- as.numeric(parts[1])
  sample_index <- match(sample_value, sort(unique(df$samples)))  # Ensure correct index
  if (parts[2] == "mirai") {
    mirai_colors[sample_index]
  } else {
    cluster_colors[sample_index]
  }
})

names(colors) <- levels(interaction_levels)

ggplot(df, 
       aes(x = cores, 
           y = speedup, 
           color = interaction(samples, type, drop = TRUE), 
           group = interaction(samples, type, drop = TRUE))) +
  geom_line() +
  geom_point(size = 2) +
  scale_x_log10(breaks = df$cores) +
  scale_y_log10() +
  scale_color_manual(values = colors) +
  labs(x = "# of cores", y = "Speedup", color = "Samples & Type") +
  ggtitle("Speedup", subtitle = "") +
  theme_grey(base_size = 14)


ggplot(df, 
       aes(x = cores, 
           y = compute_time, 
           color = interaction(samples, type, drop = TRUE), 
           group = interaction(samples, type, drop = TRUE))) +
  geom_line() +
  geom_point(size = 2) +
  scale_x_log10(breaks = df$cores) +
  scale_y_log10() +
  scale_color_manual(values = colors) +
  labs(x = "# of cores", y = "Time elapsed [s]", color = "Samples & Type") +
  ggtitle("Compute Time", subtitle = "") +
  theme_grey(base_size = 14) 


ggplot(df, 
       aes(x = cores, 
           y = setup_time, 
           color = interaction(samples, type, drop = TRUE), 
           group = interaction(samples, type, drop = TRUE))) +
  geom_line() +
  geom_point(size = 2) +
  scale_x_log10(breaks = df$cores) +
  scale_y_log10() +
  scale_color_manual(values = colors) +
  labs(x = "# of cores", y = "Time elapsed [s]", color = "Samples & Type") +
  ggtitle("Setup Time
", subtitle = "") +
  theme_grey(base_size = 14) 
```
